{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351dcc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../../')\n",
    "from src.models.cnn import AudioCNN\n",
    "from src.models.lstm import AudioLSTM\n",
    "from src.utils.config import load_config\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c077594",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c5de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config = load_config('../../configs/config.yaml')\n",
    "\n",
    "# Load preprocessed features\n",
    "processed_dir = '../../' + config['data']['processed_dir']\n",
    "features = np.load(os.path.join(processed_dir, 'features.npy'))\n",
    "labels = np.load(os.path.join(processed_dir, 'labels.npy'))\n",
    "\n",
    "print(f\"Features shape: {features.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(labels))}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  Class {label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6706fb",
   "metadata": {},
   "source": [
    "## 2. Data Splitting and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd3975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "n_samples = len(features)\n",
    "indices = np.random.permutation(n_samples)\n",
    "\n",
    "train_split = int(n_samples * config['data']['train_split'])\n",
    "val_split = int(n_samples * (config['data']['train_split'] + config['data']['val_split']))\n",
    "\n",
    "train_idx = indices[:train_split]\n",
    "val_idx = indices[train_split:val_split]\n",
    "test_idx = indices[val_split:]\n",
    "\n",
    "X_train, y_train = features[train_idx], labels[train_idx]\n",
    "X_val, y_val = features[val_idx], labels[val_idx]\n",
    "X_test, y_test = features[test_idx], labels[test_idx]\n",
    "\n",
    "print(f\"Train set: {len(X_train)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45243d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for CNN (add channel dimension)\n",
    "X_train_cnn = np.expand_dims(X_train, axis=1)  # (N, 1, H, W)\n",
    "X_val_cnn = np.expand_dims(X_val, axis=1)\n",
    "X_test_cnn = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "print(f\"CNN input shape: {X_train_cnn.shape}\")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = config['training']['batch_size']\n",
    "\n",
    "train_dataset = TensorDataset(torch.FloatTensor(X_train_cnn), torch.LongTensor(y_train))\n",
    "val_dataset = TensorDataset(torch.FloatTensor(X_val_cnn), torch.LongTensor(y_val))\n",
    "test_dataset = TensorDataset(torch.FloatTensor(X_test_cnn), torch.LongTensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"✓ Data loaders created with batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f4f0c",
   "metadata": {},
   "source": [
    "## 3. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f2d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = AudioCNN(\n",
    "    num_classes=config['model']['num_classes'],\n",
    "    input_channels=1,\n",
    "    dropout=config['model']['dropout']\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model Architecture: {config['model']['architecture'].upper()}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"\\nModel summary:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b8fd76",
   "metadata": {},
   "source": [
    "## 4. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6695b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config['training']['learning_rate'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0\n",
    "epochs_no_improve = 0\n",
    "patience = config['training']['early_stopping']['patience']\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Epochs: {config['training']['epochs']}\")\n",
    "print(f\"  Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"  Optimizer: {config['training']['optimizer']}\")\n",
    "print(f\"  Early stopping patience: {patience}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db061511",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5bd376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in tqdm(loader, desc='Training', leave=False):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(loader, desc='Validation', leave=False):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    return total_loss / len(loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0432cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 50  # Can adjust this\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        epochs_no_improve = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), '../../models/saved_models/best_model_notebook.pth')\n",
    "        print(f\"  ✓ New best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "    \n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "    print()\n",
    "\n",
    "print(f\"\\n✓ Training complete! Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa26dd6",
   "metadata": {},
   "source": [
    "## 6. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310f0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2, marker='o', markersize=4)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2, marker='s', markersize=4)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train Accuracy', linewidth=2, marker='o', markersize=4)\n",
    "axes[1].plot(history['val_acc'], label='Val Accuracy', linewidth=2, marker='s', markersize=4)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d82b4ed",
   "metadata": {},
   "source": [
    "## 7. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('../../models/saved_models/best_model_notebook.pth'))\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"TEST SET RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"{'='*50}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209ca1fb",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26aad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        _, predicted = output.max(1)\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(target.numpy())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Animal category names\n",
    "animal_categories = sorted(config['data']['animal_categories'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=animal_categories, yticklabels=animal_categories,\n",
    "            cbar_kws={'label': 'Proportion'})\n",
    "plt.title('Confusion Matrix (Normalized)', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=13)\n",
    "plt.xlabel('Predicted Label', fontsize=13)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71910d",
   "metadata": {},
   "source": [
    "## 9. Per-Class Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bfe950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-class metrics\n",
    "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "\n",
    "# Create DataFrame\n",
    "perf_df = pd.DataFrame({\n",
    "    'Animal': animal_categories,\n",
    "    'Accuracy': per_class_acc,\n",
    "    'Correct': cm.diagonal(),\n",
    "    'Total': cm.sum(axis=1)\n",
    "})\n",
    "\n",
    "perf_df = perf_df.sort_values('Accuracy', ascending=False)\n",
    "print(\"\\nPer-Class Performance:\")\n",
    "print(perf_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(range(len(animal_categories)), \n",
    "               [per_class_acc[i] for i in range(len(animal_categories))],\n",
    "               color='steelblue', alpha=0.8)\n",
    "\n",
    "# Color bars by performance\n",
    "for i, bar in enumerate(bars):\n",
    "    if per_class_acc[i] >= 0.8:\n",
    "        bar.set_color('green')\n",
    "    elif per_class_acc[i] >= 0.6:\n",
    "        bar.set_color('orange')\n",
    "    else:\n",
    "        bar.set_color('red')\n",
    "\n",
    "plt.xlabel('Animal Category', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Per-Class Classification Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(len(animal_categories)), animal_categories, rotation=45, ha='right')\n",
    "plt.ylim([0, 1])\n",
    "plt.axhline(y=0.8, color='green', linestyle='--', alpha=0.5, label='Good (≥80%)')\n",
    "plt.axhline(y=0.6, color='orange', linestyle='--', alpha=0.5, label='Fair (≥60%)')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../outputs/per_class_accuracy.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c891e2fb",
   "metadata": {},
   "source": [
    "## 10. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed classification report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(all_labels, all_preds, \n",
    "                          target_names=animal_categories, \n",
    "                          digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389539d",
   "metadata": {},
   "source": [
    "## 11. Model Summary & Next Steps\n",
    "\n",
    "### Summary:\n",
    "- **Best Validation Accuracy**: Check above\n",
    "- **Test Accuracy**: Check above\n",
    "- **Model**: CNN with mel spectrogram features\n",
    "- **Best Performing Classes**: Check per-class accuracy\n",
    "- **Worst Performing Classes**: Check per-class accuracy\n",
    "\n",
    "### Possible Improvements:\n",
    "1. **Data Augmentation**: Time shift, pitch shift, add noise\n",
    "2. **Architecture**: Try LSTM or Transformer models\n",
    "3. **Features**: Experiment with different feature types (MFCC vs Mel-spec)\n",
    "4. **Hyperparameters**: Tune learning rate, dropout, batch size\n",
    "5. **Ensemble**: Combine multiple models\n",
    "6. **Transfer Learning**: Use pre-trained audio models"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
