{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c19ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../../')\n",
    "from src.data.preprocessing import load_audio, normalize_audio\n",
    "from src.features.extractor import extract_mel_spectrogram, extract_mfcc\n",
    "from src.utils.config import load_config\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b3d5d5",
   "metadata": {},
   "source": [
    "## 1. Load Configuration and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdcf087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config('../../configs/config.yaml')\n",
    "\n",
    "# Load metadata\n",
    "metadata_path = os.path.join('../../', config['data']['data_dir'], 'meta', 'esc50.csv')\n",
    "df = pd.read_csv(metadata_path)\n",
    "\n",
    "print(f\"Total samples in ESC-50: {len(df)}\")\n",
    "print(f\"\\nDataset columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e0f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for animal sounds only\n",
    "animal_categories = config['data']['animal_categories']\n",
    "df_animals = df[df['category'].isin(animal_categories)].copy()\n",
    "\n",
    "print(f\"Animal sound samples: {len(df_animals)}\")\n",
    "print(f\"\\nAnimal categories: {sorted(animal_categories)}\")\n",
    "print(f\"\\nSamples per category:\")\n",
    "print(df_animals['category'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403f2ea9",
   "metadata": {},
   "source": [
    "## 2. Dataset Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "category_counts = df_animals['category'].value_counts().sort_index()\n",
    "axes[0].bar(range(len(category_counts)), category_counts.values, color='steelblue', alpha=0.8)\n",
    "axes[0].set_xlabel('Animal Category', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Samples', fontsize=12)\n",
    "axes[0].set_title('Animal Sound Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(range(len(category_counts)))\n",
    "axes[0].set_xticklabels(category_counts.index, rotation=45, ha='right')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "colors = plt.cm.Set3(range(len(category_counts)))\n",
    "axes[1].pie(category_counts.values, labels=category_counts.index, autopct='%1.1f%%',\n",
    "            colors=colors, startangle=90)\n",
    "axes[1].set_title('Category Distribution (%)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df054ce",
   "metadata": {},
   "source": [
    "## 3. Listen to Audio Samples\n",
    "\n",
    "Let's listen to one sample from each animal category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e4e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one sample from each category\n",
    "data_dir = '../../' + config['data']['data_dir']\n",
    "\n",
    "for category in sorted(animal_categories)[:3]:  # First 3 for demo\n",
    "    sample = df_animals[df_animals['category'] == category].iloc[0]\n",
    "    audio_path = os.path.join(data_dir, 'audio', sample['filename'])\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Category: {category.upper()}\")\n",
    "    print(f\"Filename: {sample['filename']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Load and play audio\n",
    "    audio, sr = librosa.load(audio_path, sr=config['data']['sample_rate'])\n",
    "    display(Audio(audio, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2116a1c",
   "metadata": {},
   "source": [
    "## 4. Waveform Visualization\n",
    "\n",
    "Visualize the time-domain representation of audio signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot waveforms for different animals\n",
    "fig, axes = plt.subplots(5, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, category in enumerate(sorted(animal_categories)):\n",
    "    sample = df_animals[df_animals['category'] == category].iloc[0]\n",
    "    audio_path = os.path.join(data_dir, 'audio', sample['filename'])\n",
    "    \n",
    "    audio, sr = librosa.load(audio_path, sr=config['data']['sample_rate'], duration=5)\n",
    "    \n",
    "    librosa.display.waveshow(audio, sr=sr, ax=axes[idx], color='steelblue')\n",
    "    axes[idx].set_title(f'{category.capitalize()}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Time (s)')\n",
    "    axes[idx].set_ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e04292",
   "metadata": {},
   "source": [
    "## 5. Spectrogram Analysis\n",
    "\n",
    "Spectrograms show how the frequency content of audio changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313552f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare spectrograms of 4 different animals\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "selected_animals = ['dog', 'cat', 'frog', 'rooster']\n",
    "\n",
    "for idx, category in enumerate(selected_animals):\n",
    "    sample = df_animals[df_animals['category'] == category].iloc[0]\n",
    "    audio_path = os.path.join(data_dir, 'audio', sample['filename'])\n",
    "    \n",
    "    audio, sr = librosa.load(audio_path, sr=config['data']['sample_rate'], duration=5)\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    \n",
    "    img = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz', \n",
    "                                    ax=axes[idx], cmap='viridis')\n",
    "    axes[idx].set_title(f'Spectrogram - {category.capitalize()}', fontsize=13, fontweight='bold')\n",
    "    fig.colorbar(img, ax=axes[idx], format='%+2.0f dB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88829d6",
   "metadata": {},
   "source": [
    "## 6. Mel Spectrogram Features\n",
    "\n",
    "Mel spectrograms use a perceptually-motivated scale that better represents how humans hear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ecfd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare mel spectrograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, category in enumerate(selected_animals):\n",
    "    sample = df_animals[df_animals['category'] == category].iloc[0]\n",
    "    audio_path = os.path.join(data_dir, 'audio', sample['filename'])\n",
    "    \n",
    "    audio = load_audio(audio_path, sample_rate=config['data']['sample_rate'], duration=5)\n",
    "    mel_spec = extract_mel_spectrogram(\n",
    "        audio,\n",
    "        sample_rate=config['data']['sample_rate'],\n",
    "        n_mels=config['features']['n_mels'],\n",
    "        n_fft=config['features']['n_fft'],\n",
    "        hop_length=config['features']['hop_length']\n",
    "    )\n",
    "    \n",
    "    img = librosa.display.specshow(mel_spec, sr=config['data']['sample_rate'], \n",
    "                                    x_axis='time', y_axis='mel', ax=axes[idx], cmap='magma')\n",
    "    axes[idx].set_title(f'Mel Spectrogram - {category.capitalize()}', fontsize=13, fontweight='bold')\n",
    "    fig.colorbar(img, ax=axes[idx], format='%+2.0f dB')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a42a9",
   "metadata": {},
   "source": [
    "## 7. MFCC Features\n",
    "\n",
    "MFCCs (Mel-Frequency Cepstral Coefficients) are compact representations commonly used in speech and audio recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85922fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare MFCCs\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, category in enumerate(selected_animals):\n",
    "    sample = df_animals[df_animals['category'] == category].iloc[0]\n",
    "    audio_path = os.path.join(data_dir, 'audio', sample['filename'])\n",
    "    \n",
    "    audio = load_audio(audio_path, sample_rate=config['data']['sample_rate'], duration=5)\n",
    "    mfcc = extract_mfcc(\n",
    "        audio,\n",
    "        sample_rate=config['data']['sample_rate'],\n",
    "        n_mfcc=config['features']['n_mfcc'],\n",
    "        n_fft=config['features']['n_fft'],\n",
    "        hop_length=config['features']['hop_length']\n",
    "    )\n",
    "    \n",
    "    img = librosa.display.specshow(mfcc, sr=config['data']['sample_rate'], \n",
    "                                    x_axis='time', ax=axes[idx], cmap='coolwarm')\n",
    "    axes[idx].set_title(f'MFCC - {category.capitalize()}', fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_ylabel('MFCC Coefficients')\n",
    "    fig.colorbar(img, ax=axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b1c51",
   "metadata": {},
   "source": [
    "## 8. Feature Statistics Comparison\n",
    "\n",
    "Compare statistical properties of features across different animal categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d3d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for multiple samples and compare statistics\n",
    "feature_stats = []\n",
    "\n",
    "for category in sorted(animal_categories):\n",
    "    # Get first 5 samples from each category\n",
    "    samples = df_animals[df_animals['category'] == category].head(5)\n",
    "    \n",
    "    for _, sample in samples.iterrows():\n",
    "        audio_path = os.path.join(data_dir, 'audio', sample['filename'])\n",
    "        \n",
    "        try:\n",
    "            audio = load_audio(audio_path, sample_rate=config['data']['sample_rate'], duration=5)\n",
    "            \n",
    "            # Extract MFCC\n",
    "            mfcc = extract_mfcc(audio, sample_rate=config['data']['sample_rate'])\n",
    "            \n",
    "            feature_stats.append({\n",
    "                'category': category,\n",
    "                'mfcc_mean': mfcc.mean(),\n",
    "                'mfcc_std': mfcc.std(),\n",
    "                'mfcc_max': mfcc.max(),\n",
    "                'mfcc_min': mfcc.min(),\n",
    "                'zero_crossing_rate': librosa.feature.zero_crossing_rate(audio).mean(),\n",
    "                'spectral_centroid': librosa.feature.spectral_centroid(y=audio, sr=config['data']['sample_rate']).mean(),\n",
    "                'spectral_rolloff': librosa.feature.spectral_rolloff(y=audio, sr=config['data']['sample_rate']).mean()\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "feature_df = pd.DataFrame(feature_stats)\n",
    "print(\"\\nFeature Statistics Summary:\")\n",
    "feature_df.groupby('category').mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# MFCC mean\n",
    "feature_df.boxplot(column='mfcc_mean', by='category', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('MFCC Mean Distribution', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Animal Category')\n",
    "axes[0, 0].set_ylabel('MFCC Mean')\n",
    "plt.setp(axes[0, 0].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Zero Crossing Rate\n",
    "feature_df.boxplot(column='zero_crossing_rate', by='category', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Zero Crossing Rate', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Animal Category')\n",
    "axes[0, 1].set_ylabel('ZCR')\n",
    "plt.setp(axes[0, 1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Spectral Centroid\n",
    "feature_df.boxplot(column='spectral_centroid', by='category', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Spectral Centroid', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Animal Category')\n",
    "axes[1, 0].set_ylabel('Frequency (Hz)')\n",
    "plt.setp(axes[1, 0].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Spectral Rolloff\n",
    "feature_df.boxplot(column='spectral_rolloff', by='category', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Spectral Rolloff', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Animal Category')\n",
    "axes[1, 1].set_ylabel('Frequency (Hz)')\n",
    "plt.setp(axes[1, 1].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d23ef0",
   "metadata": {},
   "source": [
    "## 9. Key Insights\n",
    "\n",
    "### Observations:\n",
    "1. **Class Balance**: All animal categories have equal representation (40 samples each)\n",
    "2. **Waveform Patterns**: Different animals show distinct temporal patterns\n",
    "3. **Frequency Characteristics**: \n",
    "   - Low-frequency animals: Cow, Pig, Frog\n",
    "   - High-frequency animals: Insects, Rooster\n",
    "4. **Feature Separability**: Mel spectrograms and MFCCs show clear differences between categories\n",
    "\n",
    "### Next Steps:\n",
    "1. Train CNN model on mel spectrogram features\n",
    "2. Experiment with data augmentation\n",
    "3. Try different model architectures (LSTM, Transformer)\n",
    "4. Analyze misclassification patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63050533",
   "metadata": {},
   "source": [
    "## 10. Export Sample Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42910e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a comprehensive visualization for presentation\n",
    "output_dir = '../../outputs/notebook_visuals'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a summary figure\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Add various plots to the summary\n",
    "# ... (code to create summary visualization)\n",
    "\n",
    "print(f\"✓ Visualizations saved to {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
